{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_JSON = 'gdrive/MyDrive/DSA4262/data.json' # Path to data.json\n",
    "DATA_INFO = 'gdrive/MyDrive/DSA4262/data.info' # Path to data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_lists = []\n",
    "\n",
    "with open(DATA_JSON) as f:\n",
    "  for transcript_json in f:\n",
    "    transcript_dict = json.loads(transcript_json)\n",
    "    for transcript_id, transcript_pos_dict in transcript_dict.items():\n",
    "      for transcript_pos, nucleotides_dict in transcript_pos_dict.items():\n",
    "        for nucleotides, data in nucleotides_dict.items():\n",
    "          transcript_lists.append([transcript_id, transcript_pos, nucleotides, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(DATA_INFO)\n",
    "labels_dict = {}\n",
    "\n",
    "for _, row in labels_df.iterrows():\n",
    "  labels_dict[row['transcript_id']] = labels_dict.get(row['transcript_id'], {})\n",
    "  labels_dict[row['transcript_id']][row['transcript_position']] = row['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_instance_idx = [] # Start and end indices of each bag where a bag is a unique combination of transcript ID and transcript position\n",
    "bag_label = []\n",
    "instance_lists = []\n",
    "instance_idx = 0\n",
    "\n",
    "for lst in transcript_lists:\n",
    "  bag_label.append(labels_dict[lst[0]][int(lst[1])])\n",
    "  bag_instance_idx.append([instance_idx, instance_idx + len(lst[3])])\n",
    "  instance_idx += len(lst[3])\n",
    "\n",
    "  for data in lst[3]:\n",
    "    instance_lists.append(lst[:3] + data + [labels_dict[lst[0]][int(lst[1])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.DataFrame(instance_lists, columns=['transcript_id', 'transcript_position', 'nucleotides', '0', '1', '2', '3', '4', '5', '6', '7', '8','label'])\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training where the model is supposed to predict the probablity that an **instance** belong to label `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBClassifier(tree_method='gpu_hist') # We can remove `tree_method` parameter if the machine does not have GPU\n",
    "xgb_model.fit(complete_df.iloc[:, 3:12], complete_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting class probabilites of each instance\n",
    "\n",
    "xgb_class_proba = xgb_model.predict_proba(complete_df.iloc[:, 3:12])\n",
    "xgb_class_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the class probabilities of each instance, we can use sum rule as described below to predict the bag labels ie. if the bag belongs to class `1` or `0`.\n",
    "\n",
    "Sum rule:\n",
    "\n",
    "$$p(+|X_i) = (1-n_i)p(+) + \\sum_{i=1}^{n_i} p(+|x_{ij})$$\n",
    "$$p(-|X_i) = (1-n_i)p(-) + \\sum_{i=1}^{n_i} p(-|x_{ij})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$n_i = Number\\;of\\;instances\\;in\\;Bag_i$$\n",
    "$$X_i = Bag_i$$\n",
    "$$x_{ij} = Instance_j\\;of\\;Bag_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_rule function works on an individual bag\n",
    "# y_instance_proba is of the shape (N_i, 2)\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "def sum_rule(y_instance_proba, pos_prior, neg_prior):\n",
    "  n_instances = len(y_instance_proba)\n",
    "  p_neg = (1 - n_instances) * (neg_prior) + np.sum(y_instance_proba[:, 0])\n",
    "  p_pos = (1 - n_instances) * (pos_prior) + np.sum(y_instance_proba[:, 1])\n",
    "\n",
    "  return softmax(np.array([p_neg, p_pos]) / (p_neg + p_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting bag labels\n",
    "\n",
    "neg_prior, pos_prior = np.unique(bag_label, return_counts=True)[1] / len(bag_label)\n",
    "predictions = []\n",
    "\n",
    "for start, end in bag_instance_idx:\n",
    "  proba = sum_rule(xgb_class_proba[start:end], pos_prior, neg_prior)\n",
    "  predictions.append(int(proba[1] > proba[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_curve, precision_recall_curve, auc\n",
    "from scipy.stats import mode\n",
    "\n",
    "def get_roc_auc(y_true, y_pred):\n",
    "    fpr, tpr, _  = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc\n",
    "\n",
    "def get_pr_auc(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    return balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ROC AUC: {get_roc_auc(bag_label, predictions)}') # ROC AUC: 0.7754103959907857\n",
    "print(f'PR AUC: {get_pr_auc(bag_label, predictions)}') # PR AUC: 0.4789541907111754\n",
    "print(f'Accuracy: {get_accuracy(bag_label, predictions)}') # Accuracy: 0.7754103959907857"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('3.9.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06896bca7bf1bedf7afe52dc08257873da07984ca27f948886f822b7d0010424"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
