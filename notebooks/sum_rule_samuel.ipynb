{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_JSON = 'gdrive/MyDrive/DSA4262/data.json' # Path to data.json\n",
    "DATA_INFO = 'gdrive/MyDrive/DSA4262/data.info' # Path to data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load existing train_gene_id and test_gene_id\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('gdrive/MyDrive/DSA4262/gtr.pickle', 'rb') as file1:\n",
    "  train_gene_id = pickle.load(file1)\n",
    "\n",
    "with open('gdrive/MyDrive/DSA4262/gte.pickle', 'rb') as file2:\n",
    "  test_gene_id = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_lists = []\n",
    "\n",
    "with open(DATA_JSON) as f:\n",
    "  for transcript_json in f:\n",
    "    transcript_dict = json.loads(transcript_json)\n",
    "    for transcript_id, transcript_pos_dict in transcript_dict.items():\n",
    "      for transcript_pos, nucleotides_dict in transcript_pos_dict.items():\n",
    "        for nucleotides, data in nucleotides_dict.items():\n",
    "          transcript_lists.append([transcript_id, transcript_pos, nucleotides, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(DATA_INFO)\n",
    "transcript_id_pos_dict = {}\n",
    "\n",
    "for _, row in labels_df.iterrows():\n",
    "  transcript_id_pos_dict[row['transcript_id']] = transcript_id_pos_dict.get(row['transcript_id'], {})\n",
    "  transcript_id_pos_dict[row['transcript_id']][row['transcript_position']] = [row['gene_id'], row['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_instance_idx = [] # Start and end indices of each bag where a bag is a unique combination of transcript ID and transcript position\n",
    "test_bag_instance_idx = [] # Same as above but for testing\n",
    "train_bag_label = []\n",
    "test_bag_label = []\n",
    "train_instance_lists = []\n",
    "test_instance_lists = []\n",
    "train_instance_idx = 0\n",
    "test_instance_idx = 0\n",
    "\n",
    "for lst in transcript_lists:\n",
    "  if transcript_id_pos_dict[lst[0]][int(lst[1])][0] in train_gene_id:\n",
    "    train_bag_label.append(transcript_id_pos_dict[lst[0]][int(lst[1])][1])\n",
    "    train_bag_instance_idx.append([train_instance_idx, train_instance_idx + len(lst[3])])\n",
    "    train_instance_idx += len(lst[3])\n",
    "\n",
    "    for data in lst[3]:\n",
    "      train_instance_lists.append(lst[:3] + data + [transcript_id_pos_dict[lst[0]][int(lst[1])][1]])\n",
    "  \n",
    "  else:\n",
    "    test_bag_label.append(transcript_id_pos_dict[lst[0]][int(lst[1])][1])\n",
    "    test_bag_instance_idx.append([test_instance_idx, test_instance_idx + len(lst[3])])\n",
    "    test_instance_idx += len(lst[3])\n",
    "\n",
    "    for data in lst[3]:\n",
    "      test_instance_lists.append(lst[:3] + data + [transcript_id_pos_dict[lst[0]][int(lst[1])][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_instance_lists, columns=['transcript_id', 'transcript_position', 'nucleotides', '0', '1', '2', '3', '4', '5', '6', '7', '8','label'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_instance_lists, columns=['transcript_id', 'transcript_position', 'nucleotides', '0', '1', '2', '3', '4', '5', '6', '7', '8','label'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features, bag labels and bag instance indices\n",
    "\n",
    "import pickle\n",
    "\n",
    "test_df.iloc[:, 3:-1].to_csv('gdrive/MyDrive/DSA4262/sum_rule_test_feature.csv', index=False)\n",
    "\n",
    "with open('gdrive/MyDrive/DSA4262/test_bag_indices.pickle', 'wb') as f:\n",
    "    pickle.dump(test_bag_instance_idx, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('gdrive/MyDrive/DSA4262/test_bag_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(test_bag_label, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training where the model is supposed to predict the probablity that an **instance** belong to label `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBClassifier(tree_method='gpu_hist')\n",
    "xgb_model.fit(train_df.iloc[:, 3:12], train_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for predicting instance probability\n",
    "\n",
    "xgb_model.save_model('gdrive/MyDrive/DSA4262/sum_rule_xgb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting class probabilites of each instance\n",
    "\n",
    "xgb_instance_proba = xgb_model.predict_proba(test_df.iloc[:, 3:12])\n",
    "xgb_instance_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the class probabilities of each instance, we can use sum rule as described below to predict the bag labels ie. if the bag belongs to class `1` or `0`.\n",
    "\n",
    "Sum rule:\n",
    "\n",
    "$$p(+|X_i) = (1-n_i)p(+) + \\sum_{i=1}^{n_i} p(+|x_{ij})$$\n",
    "$$p(-|X_i) = (1-n_i)p(-) + \\sum_{i=1}^{n_i} p(-|x_{ij})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$n_i = Number\\;of\\;instances\\;in\\;Bag_i$$\n",
    "$$X_i = Bag_i$$\n",
    "$$x_{ij} = Instance_j\\;of\\;Bag_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_rule function works on an individual bag\n",
    "# y_instance_proba is of the shape (N_i, 2)\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "def sum_rule(y_instance_proba, pos_prior, neg_prior):\n",
    "  n_instances = len(y_instance_proba)\n",
    "  p_neg = (1 - n_instances) * (neg_prior) + np.sum(y_instance_proba[:, 0])\n",
    "  p_pos = (1 - n_instances) * (pos_prior) + np.sum(y_instance_proba[:, 1])\n",
    "\n",
    "  return softmax(np.array([p_neg, p_pos]) / (p_neg + p_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting bag labels\n",
    "\n",
    "neg_prior, pos_prior = np.unique(train_bag_label, return_counts=True)[1] / len(train_bag_label)\n",
    "predictions = []\n",
    "\n",
    "for start, end in test_bag_instance_idx:\n",
    "  proba = sum_rule(xgb_instance_proba[start:end], pos_prior, neg_prior)\n",
    "  predictions.append(int(proba[1] > proba[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_curve, precision_recall_curve, auc\n",
    "from scipy.stats import mode\n",
    "\n",
    "def get_roc_auc(y_true, y_pred):\n",
    "    fpr, tpr, _  = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc\n",
    "\n",
    "def get_pr_auc(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    return balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ROC AUC: {get_roc_auc(test_bag_label, predictions)}') # ROC AUC: 0.7629566318353611\n",
    "print(f'PR AUC: {get_pr_auc(test_bag_label, predictions)}') # PR AUC: 0.47212478019287896\n",
    "print(f'Accuracy: {get_accuracy(test_bag_label, predictions)}') # Accuracy: 0.7629566318353611"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class for making predictions using the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumRule:\n",
    "  import numpy\n",
    "  import scipy\n",
    "  \n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  def sum_rule(self, y_instance_proba, pos_prior, neg_prior):\n",
    "    n_instances = len(y_instance_proba)\n",
    "    p_neg = (1 - n_instances) * (neg_prior) + self.numpy.sum(y_instance_proba[:, 0])\n",
    "    p_pos = (1 - n_instances) * (pos_prior) + self.numpy.sum(y_instance_proba[:, 1])\n",
    "\n",
    "    return self.scipy.special.softmax(self.numpy.array([p_neg, p_pos]) / (p_neg + p_pos))\n",
    "\n",
    "\n",
    "  def predict(self, features, bag_indices, pos_prior=0.04427960226597472, neg_prior=0.9557203977340253):\n",
    "    instance_proba = self.model.predict_proba(features)\n",
    "    predictions = []\n",
    "\n",
    "    for start, end in bag_indices:\n",
    "      proba = self.sum_rule(instance_proba[start:end], pos_prior, neg_prior)\n",
    "      predictions.append(int(proba[1] > proba[0]))\n",
    "\n",
    "    return self.numpy.array(predictions)\n",
    "\n",
    "  def predict_proba(self, features, bag_indices, pos_prior=0.04427960226597472, neg_prior=0.9557203977340253):\n",
    "    instance_proba = self.model.predict_proba(features)\n",
    "    bag_proba = []\n",
    "\n",
    "    for start, end in bag_indices:\n",
    "      proba = self.sum_rule(instance_proba[start:end], pos_prior, neg_prior)\n",
    "      bag_proba.append(proba[1])\n",
    "\n",
    "    return self.numpy.array(bag_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the created class to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "features = pd.read_csv('gdrive/MyDrive/DSA4262/sum_rule_test_feature.csv')\n",
    "\n",
    "with open('gdrive/MyDrive/DSA4262/test_bag_indices.pickle', 'rb') as f:\n",
    "  bag_indices = pickle.load(f)\n",
    "\n",
    "with open('gdrive/MyDrive/DSA4262/test_bag_labels.pickle', 'rb') as f:\n",
    "  bag_labels = pickle.load(f)\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.load_model('gdrive/MyDrive/DSA4262/sum_rule_xgb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_rule_model = SumRule(xgb_model)\n",
    "\n",
    "predictions = sum_rule_model.predict(features, bag_indices)\n",
    "prediction_proba = sum_rule_model.predict_proba(features, bag_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "06896bca7bf1bedf7afe52dc08257873da07984ca27f948886f822b7d0010424"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
